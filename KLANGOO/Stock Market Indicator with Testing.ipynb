{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd300e87",
   "metadata": {},
   "source": [
    "# Stock market Indicator Using Klangoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57b9c1",
   "metadata": {},
   "source": [
    "### This is a prototype to demonsrate the use of Klangoo in stock indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2538d",
   "metadata": {},
   "source": [
    "### Define a function that will be used in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f24055d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_common(x,y):\n",
    "   common = False\n",
    "   for value in x:\n",
    "      if value in y:\n",
    "         common= True\n",
    "   return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68a1b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let this the last part, if you have time you can do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcb039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43820d75",
   "metadata": {},
   "source": [
    "### Import Libraries and read csv as a dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f0f2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from klangooclient.MagnetAPIClient import MagnetAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc40de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweets_labelled.csv\") #Read  csv file containig 5000 tweets and the sentiment of each tweet                                                      # The csv file from kaggle contains alreade the sentiment analysis \n",
    "df = df[:10] #30 in testing  #ONly 2000 tweets will be maniupulated bcz we have only 5000 requests from kalngoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d318ea",
   "metadata": {},
   "source": [
    "### Prepare connection strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4f05caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT ='https://nlp.klangoo.com/Service.svc'\n",
    "CALK = '155b99fc-758c-40c8-a8ef-5d4eb9fba616'\n",
    "SECRET_KEY = 'wTMeUVHL38vGrdDBbSdSFBQOWFchPTaUnIFZBJS4'\n",
    "\n",
    "client = MagnetAPIClient(ENDPOINT, CALK, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ef12f",
   "metadata": {},
   "source": [
    "### Specify wanted entities and categories to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3523231",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_entities = ['amazon', 'amzn'] #Stock(s) interrested in, This option is subjective to the user.\n",
    "wanted_categories = ['general','business', \\\n",
    "                     ,'science','politics',\\\n",
    "                     'technology'] # Only texts having these categoreis will be taken into considertion\n",
    "                                            # Buisness, and also politics news are very important to the stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110dc313",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bda18829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "RT @vincent13031925: Biggest mistakes of the century: From before  Apple AAPL is  only a PC maker  Amazon AMZN is only a bookstore Gooâ€¦\n",
      "negative\n",
      "entities_nb:  3\n",
      "text_entities:  ['amazon', 'apple', 'rt']\n",
      "text_categories:  ['technology', 'business']\n",
      "check_category:  True\n",
      "check_entities:  True\n",
      "========\n",
      "1\n",
      "RT @BarrySchwartzBW: Carl Icahn once owned 10% of Netflix. That stake today would have been worth about 24B. He also had 52m shares of Appâ€¦\n",
      "neutral\n",
      "entities_nb:  2\n",
      "text_entities:  ['carl icahn', 'netflix']\n",
      "text_categories:  ['business', 'technology']\n",
      "check_category:  True\n",
      "check_entities:  False\n",
      "========\n",
      "2\n",
      "RT @gzbenso: Netflix leads its rivals in original TV shows by a wide margin in both quantity and quality  according to new data analysis htâ€¦\n",
      "positive\n",
      "entities_nb:  1\n",
      "text_entities:  ['netflix']\n",
      "text_categories:  ['technology']\n",
      "check_category:  True\n",
      "check_entities:  False\n",
      "========\n",
      "3\n",
      "RT @iflickerman: \"All Free\" Retail is Back  Amazon AMZN ready for Chapter 11 ðŸ¤£ðŸ¤£ðŸ¤£ @JuliaLaRoche https://t.co/t4S8BD3REg\n",
      "positive\n",
      "entities_nb:  2\n",
      "text_entities:  ['amazon', 'rt']\n",
      "text_categories:  ['business']\n",
      "check_category:  True\n",
      "check_entities:  True\n",
      "========\n",
      "4\n",
      "RT @ReformedBroker: Amazon is less than 2% away from a record high. AMZN is 10% or so of the QQQs https://t.co/ejWq3o2AuA\n",
      "positive\n",
      "entities_nb:  1\n",
      "text_entities:  ['amazon']\n",
      "text_categories:  ['science']\n",
      "check_category:  False\n",
      "check_entities:  True\n",
      "========\n",
      "5\n",
      "Netflix is so overvalued  the stock is gonna collapse when people realise stocks StockMarket\n",
      "negative\n",
      "entities_nb:  1\n",
      "text_entities:  ['netflix']\n",
      "text_categories:  ['technology']\n",
      "check_category:  True\n",
      "check_entities:  False\n",
      "========\n",
      "6\n",
      "MSFT Microsoft all time highs\n",
      "AMZN Amazon all time highs \n",
      "NFLX Netflix all time highs\n",
      "FB Facebook all time highs\n",
      "APPL Apple all time highs\n",
      "GOOGL Google nearly all time highs\n",
      "Talk about the big boys doing the heavy lifting\n",
      "positive\n",
      "entities_nb:  6\n",
      "text_entities:  ['microsoft', 'amazon', 'apple', 'google', 'netflix', 'facebook']\n",
      "text_categories:  ['technology']\n",
      "check_category:  True\n",
      "check_entities:  True\n",
      "========\n",
      "7\n",
      "RT @DanaMattioli: Amazon says it doesnt use information on third-party sellers to inform its private-label business. But interviews with mâ€¦\n",
      "neutral\n",
      "entities_nb:  1\n",
      "text_entities:  ['amazon']\n",
      "text_categories:  ['business']\n",
      "check_category:  True\n",
      "check_entities:  True\n",
      "========\n",
      "8\n",
      "Amazon isnâ€™t the only e-commerce company thriving. AMZN shares have climbed &gt,30% this year. But some online retailers are faring even better. Shares of Wayfair  the online furniture and home goods seller  have doubled in price in 2020. /via @qz https://t.co/GQOmMzgcF9\n",
      "positive\n",
      "entities_nb:  1\n",
      "text_entities:  ['amazon']\n",
      "text_categories:  ['business']\n",
      "check_category:  True\n",
      "check_entities:  True\n",
      "========\n",
      "9\n",
      "spy gspc aapl nflx goog tsla Financial stocks reverse course  as J.P. Morgan and Wells Fargo shares swing to losses  https://t.co/6NRdAue7ZU\n",
      "negative\n",
      "entities_nb:  4\n",
      "text_entities:  ['goog', 'j.p. morgan', 'wells fargo', 'gspc']\n",
      "text_categories:  ['business']\n",
      "check_category:  True\n",
      "check_entities:  False\n",
      "========\n",
      "The Netflix stock have a positive Semantic Analysis in the given tweets, Think of buying or hloding. After         processing  5  tweets, the term Netfilx or NFLX got a scrore of :  2.0  on 5 .\n"
     ]
    }
   ],
   "source": [
    "n = len(df)\n",
    "ctr = 0\n",
    "grade_sum = 0\n",
    "final_grade = 0\n",
    "\n",
    "for i in range(n): #read all the tweets from  the dataFrame\n",
    "    text = df.iloc[i,2] #get text from dataFrame\n",
    "    sentiment = df.iloc[i,3]   #get sentiment analysis result from dataFrame\n",
    "        \n",
    "    request =  { 'text' : text, 'lang' : 'en', 'format' : 'json' }\n",
    "    rsp = client.callwebmethod('ProcessDocument', request, 'POST') #Use Klangoo to get all entities and categories of tweet\n",
    "    info = json.loads(rsp) #transform from Bytes to Json format\n",
    "    info.fromkeys\n",
    "    \n",
    "    entities_nb = len(info['document']['entities'])\n",
    "    categories_nb = len(info['document']['categories']) \n",
    "    \n",
    "    text_entities = []   # get the key topics from text and append to this list\n",
    "    text_categories = []   # get the categories from text and append to this list \n",
    "    \n",
    "    for j in range(entities_nb):\n",
    "        text_entities.append(info['document']['entities'][j]['token'].lower() ) # append the entities to the list\n",
    "    \n",
    "    for j in range(categories_nb):\n",
    "        text_categories.append(info['document']['categories'][j]['name'].lower() ) # append the key categories to the list\n",
    "    \n",
    "    check_category = have_common(wanted_categories, text_categories ) #check existecne of an item of text_categories in wanted_category \n",
    "    check_entities = have_common(wanted_entities, text_entities )\n",
    "    \n",
    "    \n",
    "    print(i)\n",
    "    print(text)\n",
    "    print(sentiment)\n",
    "    print(\"entities_nb: \", entities_nb)\n",
    "    print(\"text_entities: \" , text_entities)\n",
    "    print(\"text_categories: \", text_categories)\n",
    "    \n",
    "    check_category = have_common(wanted_categories, text_categories ) #check existecne of an item of text_categories in wanted_category \n",
    "    check_entities = have_common(wanted_entities, text_entities )\n",
    "    print(\"check_category: \", check_category)\n",
    "    print(\"check_entities: \" , check_entities)\n",
    "    print(\"========\")\n",
    "    \n",
    "    if check_category  and check_entities: # if the category and topics of the text are in what we are interrested in \n",
    "        if sentiment == 'positive':\n",
    "            grade_sum += 5   \n",
    "        elif sentiment == 'negative':\n",
    "            grade_sum -= 5\n",
    "        #else is: stays zero \n",
    "        ctr += 1\n",
    "          \n",
    "  \n",
    "\n",
    "if ctr != 0:\n",
    "    final_grade = grade_sum / ctr\n",
    "\n",
    "    if final_grade <0:\n",
    "        print(\"The Amazon stock have negative Semantic Analysis in the given tweets, Think of selling. After \\\n",
    "        processing \", ctr , \" tweets, the term Netfilx or NFLX got a scrore of : \" , final_grade, \" on 5 .\")\n",
    "    elif final_grade >0:\n",
    "        print(\"The Amazon stock have a positive Semantic Analysis in the given tweets, Think of buying or hloding. After \\\n",
    "        processing \", ctr , \" tweets, the term Netfilx or NFLX got a scrore of : \" , final_grade, \" on 5 .\")\n",
    "    else:\n",
    "        print(\"The Amazon stock have a neutral Semantic Analysis. \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3eab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When the entity is amazon the klangoo is giving empty string as response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed3ec63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['A', 'b']\n",
    "\n",
    "b= ['A']\n",
    "have_common(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bbe2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaee7813",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "455bd98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trajectory of the Bitcoin (BTC) kept crypto traders, investors, and enthusiasts guessing as a July 15 relief rally registered a high of $21,140. Bitcoin continues to trade in the $20,000-22,000 range. The US CPI data that pegged its quarterly inflation at 9.1%, the highest in 40 years, seems to not have affected the markets as yet. BTC and other crypto assets are following the global stock indices which have been in the green in the second half of the wee\n",
      "entities:  ['bitcoin', 'us']\n",
      "categories:  ['business']\n"
     ]
    }
   ],
   "source": [
    "from klangooclient.MagnetAPIClient import MagnetAPIClient\n",
    "import json\n",
    "text = 'The trajectory of the Bitcoin (BTC) kept crypto traders, investors, and enthusiasts guessing as a July 15 relief rally registered a high of $21,140. Bitcoin continues to trade in the $20,000-22,000 range. The US CPI data that pegged its quarterly inflation at 9.1%, the highest in 40 years, seems to not have affected the markets as yet. BTC and other crypto assets are following the global stock indices which have been in the green in the second half of the wee'\n",
    "\n",
    "text.replace('\\n', ' ').replace('\\r', '')\n",
    "text = text.strip()\n",
    "print(text)\n",
    "request = { 'text' :text ,\n",
    "           'lang' : 'en', 'format' : 'json' }\n",
    "\n",
    "rsp = client.callwebmethod('ProcessDocument', request, 'POST')\n",
    "info = json.loads(rsp) #transform from Bytes to dictionary\n",
    "info.fromkeys\n",
    "\n",
    "#get all the key topics from the text\n",
    "entities_nb = len(info['document']['entities'])\n",
    "categories_nb = len(info['document']['categories'])\n",
    " \n",
    "\n",
    "entities = [] # get the key topics from text and append to this list\n",
    "categories = [] # get the categories from text and append to this list\n",
    " \n",
    "\n",
    "for i in range(entities_nb):\n",
    "    entities.append(info['document']['entities'][i]['token'].lower() )\n",
    "    \n",
    "for i in range(categories_nb):\n",
    "    categories.append(info['document']['categories'][i]['name'].lower())\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"entities: \", entities)  \n",
    "print(\"categories: \", categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bfcf86e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'ProcessDocument', 'status': 'OK', 'document': {'properties': {'lang': 'en'}, 'summary': 'The trajectory of the Bitcoin (BTC) kept crypto traders, investors, and enthusiasts guessing as a July 15 relief rally registered a high of $21,140 . ', 'keyTopics': [{'text': 'Bitcoin', 'score': 1, 'words': [{'token': 'bitcoin', 'conceptID': 127564, 'wikiID': 'Bitcoin'}]}, {'text': 'July 15 relief rally', 'score': 0.7466, 'words': [{'token': 'july', 'conceptID': 80933}, {'token': 'relief', 'conceptID': 5508}, {'token': 'rally', 'conceptID': 45081}]}, {'text': 'US CPI data', 'score': 0.7466, 'words': [{'token': 'us', 'conceptID': 48186, 'wikiID': 'United_States'}, {'token': 'cpi', 'conceptID': 35508}, {'token': 'data', 'conceptID': 45570}]}, {'text': 'second-half', 'score': 0.7466, 'words': [{'token': 'second-half', 'conceptID': 81194}]}, {'text': 'quarterly inflation', 'score': 0.6848, 'words': [{'token': 'quarterly', 'conceptID': 80901}, {'token': 'inflation', 'conceptID': 71543}]}, {'text': 'global stock indices', 'score': 0.6848, 'words': [{'token': 'global', 'conceptID': 26293}, {'token': 'stock_index', 'conceptID': 35510}]}, {'text': 'trajectory', 'score': 0.6181, 'words': [{'token': 'trajectory', 'conceptID': 61840}]}, {'text': 'traders', 'score': 0.6181, 'words': [{'token': 'trader', 'conceptID': 57653}]}, {'text': 'investors', 'score': 0.6181, 'words': [{'token': 'investor', 'conceptID': 54706}]}, {'text': 'enthusiasts', 'score': 0.6181, 'words': [{'token': 'enthusiast', 'conceptID': 53849}]}], 'entities': [{'token': 'Bitcoin', 'typeID': '24', 'type': 'Scale/unit', 'entityID': 127564, 'conceptID': 127564, 'score': 0.9669, 'wikiID': 'Bitcoin', 'rank': 'VR'}, {'token': 'US', 'typeID': '37', 'type': 'Countries', 'entityID': 45068, 'conceptID': 48186, 'score': 0.9077, 'wikiID': 'United_States', 'rank': 'VR'}], 'categories': [{'name': 'Business'}]}}\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b5b9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['method', 'status', 'document']) \n",
      "\n",
      "dict_keys(['properties', 'summary', 'keyTopics', 'entities', 'categories']) \n",
      "\n",
      "key topics:   {'text': 'safety app', 'score': 0.9402, 'words': [{'token': 'safety', 'conceptID': 77199}, {'token': 'app', 'conceptID': 35108}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'real-time audio chat apps', 'score': 0.6518, 'words': [{'token': 'real-time', 'conceptID': 81417}, {'token': 'audio', 'conceptID': 14611}, {'token': 'chat', 'conceptID': 33648}, {'token': 'app', 'conceptID': 35108}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'meaningful conversation', 'score': 0.6274, 'words': [{'token': 'meaningful', 'conceptID': 28365}, {'token': 'conversation', 'conceptID': 38254}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'social audio apps Clubhouse', 'score': 0.6009, 'words': [{'token': 'social', 'conceptID': 43254}, {'token': 'audio', 'conceptID': 14611}, {'token': 'app', 'conceptID': 35108}, {'token': 'clubhouse', 'conceptID': 16410}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'user', 'score': 0.5929, 'words': [{'token': 'user', 'conceptID': 57794}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': \"Truecaller's parent company\", 'score': 0.5089, 'words': [{'token': 'parent', 'conceptID': 55808}, {'token': 'company', 'conceptID': 43624}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'friend', 'score': 0.4696, 'words': [{'token': 'friend', 'conceptID': 54063}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': \"conversation's direction\", 'score': 0.4481, 'words': [{'token': 'conversation', 'conceptID': 38254}, {'token': 'direction', 'conceptID': 36273}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'Latin', 'score': 0.4446, 'words': [{'token': 'latin', 'conceptID': 54892}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'Open Doors', 'score': 0.4423, 'words': [{'token': 'open_doors', 'conceptID': 28415}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'rooms', 'score': 0.4314, 'words': [{'token': 'room', 'conceptID': 22551}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'Spotify', 'score': 0.4051, 'words': [{'token': 'spotify', 'conceptID': 98245}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'parties', 'score': 0.4045, 'words': [{'token': 'party', 'conceptID': 55828}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'moderation tools', 'score': 0.3563, 'words': [{'token': 'moderation', 'conceptID': 28104}, {'token': 'tool', 'conceptID': 35092}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'folks', 'score': 0.3427, 'words': [{'token': 'folk', 'conceptID': 43157}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'Android', 'score': 0.3412, 'words': [{'token': 'android', 'conceptID': 83563, 'wikiID': 'Android_(operating_system)'}]} \n",
      "\n",
      "\n",
      "key topics:   {'text': 'houses', 'score': 0.335, 'words': [{'token': 'house', 'conceptID': 24422}]} \n",
      "\n",
      "\n",
      "0.5113\n"
     ]
    }
   ],
   "source": [
    "print(info.keys(),\"\\n\" )\n",
    "print(info['document'].keys()   ,\"\\n\"  )\n",
    "for i in range(len(info['document']['keyTopics'])):\n",
    "    print(\"key topics:  \", info['document']['keyTopics'][i]    ,\"\\n\\n\")\n",
    "print(info['document']['entities'][0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "92383fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_entities:  ['amazon', 'covid-19', 'dollar general', 'walmart']\n",
      "text_categories:  ['business', 'health']\n",
      "key_topics:  ['amzn shares', 'only e-commerce company', 'amazon', 'online retailers', 'home commodities seller', 'price', 'wayfairthe online furniture']\n"
     ]
    }
   ],
   "source": [
    "print(\"text_entities: \" , text_entities)  \n",
    "print(\"text_categories: \" , text_categories)\n",
    "print(\"key_topics: \" , key_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "922d00de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catogories:  ['business']\n",
      "wanted_categories:  ['general', 'business', 'politics', 'technology']\n",
      "entities:  ['amazon']\n",
      "user_important_stocks:  ['amazon', 'amzn']\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "check_category = any(item in wanted_categories for item in categories)#check existecne of an item of text_categories in wanted_category \n",
    "check_topics = any( item in entities for item in user_important_stocks )\n",
    "print(\"catogories: \" , categories)\n",
    "print(\"wanted_categories: \" , wanted_categories)\n",
    "\n",
    "print(\"entities: \", entities)\n",
    "print(\"user_important_stocks: \", user_important_stocks)\n",
    "\n",
    "print(check_category, check_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "47a11fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final step\n",
      "ctr:  1\n",
      "grade_sum:  -5\n",
      "['business', 'health']\n",
      "['amazon', 'covid-19', 'dollar general', 'walmart']\n"
     ]
    }
   ],
   "source": [
    "check_category = any(item in wanted_categories for item in text_categories)#check existecne of an item of text_categories in wanted_category \n",
    "check_entities = any( item in user_important_stocks for item in text_entities )\n",
    "if check_category  and check_entities: # if the category and topics of the text is in what we are interrested in \n",
    "    print(\"Final step\")\n",
    "    grade = 0\n",
    "    if sentiment =='positive':\n",
    "        grade = 5\n",
    "    elif sentiment =='negative':\n",
    "        grade = -5\n",
    "    #else is stays zero \n",
    "    ctr += 1\n",
    "    grade_sum += grade\n",
    "print(\"ctr: \" , ctr)\n",
    "print(\"grade_sum: \" ,grade_sum)\n",
    "\n",
    "print(text_categories)\n",
    "print(text_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38a0a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Its time to start stacking bitcoin again. Thats the message from indicators tracking tokens sold by miners and comparing the cryptoc\\\n",
    "urrencys market value to its fair value.\\\n",
    "The Puell Multiple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08cea79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Its/PRP$\n",
      "  time/NN\n",
      "  to/TO\n",
      "  start/VB\n",
      "  stacking/VBG\n",
      "  bitcoin/RB\n",
      "  again/RB\n",
      "  ./.\n",
      "  Thats/VB\n",
      "  the/DT\n",
      "  message/NN\n",
      "  from/IN\n",
      "  indicators/NNS\n",
      "  tracking/VBG\n",
      "  tokens/NNS\n",
      "  sold/VBN\n",
      "  by/IN\n",
      "  miners/NNS\n",
      "  and/CC\n",
      "  comparing/VBG\n",
      "  the/DT\n",
      "  cryptocurrencys/NN\n",
      "  market/NN\n",
      "  value/NN\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  fair/JJ\n",
      "  value.The/NN\n",
      "  (PERSON Puell/NNP Multiple/NNP))\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(s)\n",
    "#print(tokens)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dce946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0cec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038747e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "077bdadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94790cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "894841e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68244246",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ 1, 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577a60ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'a']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b87f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25ee3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [i for i in range(1000)]\n",
    "f =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2174c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100000000)\n",
    "y = np.random.rand(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fc0e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25009017.01451841\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000000):\n",
    "    f += x[i]*y[i]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f537560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25001458.48211907\n"
     ]
    }
   ],
   "source": [
    "f = np.dot(x,y)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9b7d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "a = [4,5,6]\n",
    "b = a\n",
    "a = [1,2,3]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0aaa967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "z = analyser.polarity_scores(\"As of now, the second-largest crypto trades at just over $1,050. BNB went from over $240 to below $220 in the same timeframe, but a minor daily increase has pushed the asset to $226 as of now. Ripple, Solana, Polkadot, Tron, Shiba Inu, and LEO are also slightly in the green today. Cardano and Dogecoin, on the other hand, have charted insignificant declines. Most lower- and mid-cap alts are also quite calm. ApeCoin is among the few impressive gainers with a 6% daily increase. Consequently, APE trades just over $4.5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d9d4b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.059, 'neu': 0.743, 'pos': 0.198, 'compound': 0.9428}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d20e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_influencers = ['elon musk', 'nick black', 'allan mantaring','jordan belfort','Tangie Seals','Rowan McInnes'\\\n",
    "                   'Mark Minervini', 'Vic Scherer'  'Steve Sturner','Brittney Castro','Garrett Ashe',\\\n",
    "                   'Raja Al Mazrouei','Chamath Palihapitiya','Cathie Wood','Dave Portnoy'\\\n",
    "                   ,'Oliver L. Velez','John Bollinger','Robert Ross','Kayla Kilbride','Errol Coleman','Timothy Sykes'\\\n",
    "                   ,'Kritika Yadav','Trajan King','Denis Stelmak','Patrick Wieland'] \n",
    "#The most trusted newspapers in the domain of stock exchange\n",
    "Trusted_resources = [ 'Moneycontrol', 'The economic Times', 'Bloomberg Quint', 'Reuters'\\\n",
    "                    'Livemint', 'Buisness Standard', 'Google Finance', 'NDTV Profit', 'Yahoo Finance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8fb952d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Trusted_resources)):\n",
    "    Trusted_resources[i] = Trusted_resources[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a812db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moneycontrol', 'the economic times', 'bloomberg quint', 'reuterslivemint', 'buisness standard', 'google finance', 'ndtv profit', 'yahoo finance']\n"
     ]
    }
   ],
   "source": [
    "print(Trusted_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42106b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
