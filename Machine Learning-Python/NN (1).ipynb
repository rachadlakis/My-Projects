{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3625ba-bbd5-417f-8432-827334875b8d",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7595e79-b81f-42c9-91b8-a033493b7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3704a-cc9c-4e19-ad22-74aa3f0a2d25",
   "metadata": {},
   "source": [
    "### Activation  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b384ee9-806c-4534-aa54-88d438b9f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return (1 / (1+ np.exp(-v)) )\n",
    "def threshold(v):\n",
    "    if v < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def tanh(v):\n",
    "    return( 1-np.exp(-v) / ( 1 + np.exp(-v) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991f176-9897-41c9-a27e-c002d7545050",
   "metadata": {},
   "source": [
    "### Try in random simple input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c68b0c2-ed63-480c-8e26-f130961d712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example values\n",
    "input_nb = 3\n",
    "L1_n = 4 # nb of neurons in Layer 1\n",
    "L2_n = 4 # nb of neurons in Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0483bd14-bab6-44e0-8c1d-c565a2cf0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.rand(input_nb)    # input is a numpy array of shape (n,), we should add +1 to the array for the bias\n",
    "\n",
    "#matrix W1 is of shape rows = nb of cols of previous array, cols = nb of neurons we want to make\n",
    "W1 = np.random.rand(input_nb +1 ,L1_n)  \n",
    "W2 = np.random.rand(L1_n+1, L2_n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cf8eff-1b64-41fb-8209-35609ab1c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 without bias: [0.5645 0.7655 0.2019]\n",
      "shape of X1 (3,) \n",
      "\n",
      "W1:\n",
      " [[0.1882 0.2387 0.1158 0.902 ]\n",
      " [0.8861 0.9866 0.7955 0.1544]\n",
      " [0.9064 0.8246 0.3111 0.158 ]\n",
      " [0.3424 0.3009 0.3289 0.3468]]\n",
      "shape of W1: (4, 4) \n",
      "\n",
      "W2:,\n",
      " [[0.7952 0.7318 0.0452 0.2742]\n",
      " [0.8526 0.3544 0.741  0.9427]\n",
      " [0.4656 0.6707 0.9042 0.0146]\n",
      " [0.1055 0.4706 0.9328 0.4938]\n",
      " [0.0777 0.763  0.7502 0.7391]]\n",
      "shape of W2:  (5, 4) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X1 without bias:\",X1)\n",
    "print(\"shape of X1\" , X1.shape,\"\\n\")\n",
    "\n",
    "print(\"W1:\\n\", W1)\n",
    "print(\"shape of W1:\", W1.shape, \"\\n\")\n",
    "print(\"W2:,\\n\", W2)\n",
    "print(\"shape of W2: \", W2.shape, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53a9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 with bias:  [0.5645 0.7655 0.2019 1.    ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X1 = np.append(X1,1) #add +1 to end of X for the bias\n",
    "print(\"X1 with bias: \", X1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7c45d8-8cad-4f15-bc06-e4b982564080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward propagation takes an input X, a matrix representing the coeficiants of neurons, and an activation function\n",
    "def forward_prop(X,W,fn=sigmoid):\n",
    "    X_length = X.shape[0] #length of X \n",
    "    W_rows,W_cols = W.shape #nb of rows and columns on matrix W    \n",
    "    if W_rows != X_length:\n",
    "        print(\"Not proprtional size\")\n",
    "        return\n",
    "    output = np.zeros(W_cols)\n",
    "    for i in range(W_cols): \n",
    "        output[i] = fn( (np.dot(X, W[:,i]) )) #the sigmoid of the scalar product of X and column i of W\n",
    "           \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb165e2-ecf7-45f8-afc0-053ad7246589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:  [[0.1882 0.2387 0.1158 0.902 ]\n",
      " [0.8861 0.9866 0.7955 0.1544]\n",
      " [0.9064 0.8246 0.3111 0.158 ]\n",
      " [0.3424 0.3009 0.3289 0.3468]]\n",
      "Y1 wihtout Bias:  [0.7875 0.7953 0.7438 0.7323]\n",
      "Y1 with bias:  [0.7875 0.7953 0.7438 0.7323 1.    ]\n",
      "Y2: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#TRY forward_prop\n",
    "print(\"w1: \", W1)\n",
    "Y1 = forward_prop(X1,W1,sigmoid)\n",
    "print(\"Y1 wihtout Bias: \", Y1)\n",
    "\n",
    "Y1 = np.append(Y1,1)\n",
    "print(\"Y1 with bias: \", Y1)\n",
    "Y2 = forward_prop(Y1, W2, threshold)\n",
    "print(\"Y2:\" , Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ecfc4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 with bias:\n",
      " [0.7626 0.1639 0.198  1.    ]\n",
      "w1:\n",
      " [[0.4596 0.9449 0.385  0.0526]\n",
      " [0.7746 0.7359 0.0659 0.8647]\n",
      " [0.5288 0.4026 0.7178 0.0466]\n",
      " [0.8678 0.05   0.7516 0.3112]] \n",
      "\n",
      "Y1:\n",
      " [0.81   0.7253 0.7682 0.623  1.    ] \n",
      "\n",
      "Y1 with bias:\n",
      " [0.81   0.7253 0.7682 0.623  1.    ] \n",
      "\n",
      "Y2:\n",
      " [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"X1 with bias:\\n\", X1)\n",
    "print(\"w1:\\n\", W1,\"\\n\")\n",
    "print(\"Y1:\\n\", Y1,\"\\n\")\n",
    "print(\"Y1 with bias:\\n\", Y1,\"\\n\")\n",
    "print(\"Y2:\\n\" , Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45071212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Back Propagation\n",
    "def back_prop(X,W,d,eta=1,fn=sigmoid):\n",
    "    X_length = X.shape[0] #length of X \n",
    "    y = forward_prop(X,W,fn)\n",
    "    W_rows,W_cols = W.shape #nb of rows and columns on matrix W \n",
    "    n = d.shape[0] \n",
    "    e_n = np.zeros_like(y)\n",
    "    for i in range(n):\n",
    "        e_n[i]=d[i]-y[i] #error vector for all outputs (their nb is equal to nb of neurons of previous layer)\n",
    "        \n",
    "    for i in range(W_cols): #rectify values of each value of each column of W\n",
    "        W_i =  W[:,i]\n",
    "        for j in range(W_i.shape[0]):\n",
    "            W_i[j] = W_i[j] + (eta * (e_n[i]*X[j])  )\n",
    "        W[:,i] = W_i\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464a9494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "desired_Y=np.array([1,0,1,1])\n",
    "print(desired_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207dd4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:\n",
      " [[0.1882 0.2387 0.1158 0.902 ]\n",
      " [0.8861 0.9866 0.7955 0.1544]\n",
      " [0.9064 0.8246 0.3111 0.158 ]\n",
      " [0.3424 0.3009 0.3289 0.3468]] \n",
      "\n",
      "W1 after backprop one time:\n",
      " [[ 0.3081 -0.2103  0.2604  1.0531]\n",
      " [ 1.0488  0.3778  0.9916  0.3594]\n",
      " [ 0.9494  0.664   0.3628  0.2121]\n",
      " [ 0.5549 -0.4944  0.585   0.6146]]\n"
     ]
    }
   ],
   "source": [
    "#W1 before and after one backpropagation\n",
    "print(\"w1:\\n\" ,W1, \"\\n\")\n",
    "W1_after_back_prop = back_prop(X1,W1,desired_Y,1)\n",
    "print(\"W1 after backprop one time:\\n\" , W1_after_back_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6941b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: If we have many layers, what is desired y in layers beofre the last one??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95f04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, yhat):\n",
    "    m =len(y)\n",
    "    err = 0.0\n",
    "    for i in range(m):\n",
    "        err += np.square(y[i]-yhat[i])\n",
    "    err = (1/2*m)*err\n",
    "    return(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517a8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5; ctr =0\n",
    "W_temp = W1\n",
    "\n",
    "while ctr<epochs:\n",
    "    W_temp = back_prop(X1,W_temp,desired_Y,1)\n",
    "    ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ad1282-a710-458b-9b69-0bd0753bf697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired Y:  [1 0 1 1]\n",
      "Predicted value: [1. 0. 1. 1.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_Y = forward_prop(X1,W_temp,threshold)\n",
    "print(\"Desired Y: \", desired_Y)\n",
    "print(\"Predicted value:\" , predicted_Y,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06b9bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(desired_Y, predicted_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f54fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
