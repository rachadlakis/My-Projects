{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0484b-9650-4b55-806d-41fc834c1140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c82016-80dd-4168-94a4-b3b39f04e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model, model_from_json, load_model, Sequential\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization,MaxPooling2D, Input, Concatenate, Dense, Dropout, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9a4073-164e-45cb-9a3e-fc48df653543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d274d611-2002-4136-835a-8d924169e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3809715622323802958\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2956456756\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10678836705668570121\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187b2874-6e76-4c0c-b737-53f67ec8e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "physical_devices= tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fa76f2-9c55-427f-871f-5a7ee9833b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'E:/DataSets/affect_net_sample_archive/train_class'\n",
    "validation_dir ='E:/DataSets/affect_net_sample_archive/val_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920556a-1e75-48ca-9393-0388ed8365c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207e2889-07d1-4b11-aeae-6e7005e0a554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 177, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See image shape with matplotlib.pylot\n",
    "img = plt.imread(os.path.join(train_dir,'class001\\image0000002.jpg'))\n",
    "img.shape\n",
    "#print(img)\n",
    "#print(img/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a847118-d199-4dd8-8b04-186789735d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_aug = ImageDataGenerator(rescale = 1./255,\n",
    "                                      rotation_range=40,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      fill_mode='nearest')\n",
    "\n",
    "valid_datagen_aug = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c4e3bf-fa76-4607-a773-d80d71e47205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37553 images belonging to 8 classes.\n",
      "Found 4000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator_aug = train_datagen_aug.flow_from_directory(train_dir,\n",
    "                                                    target_size=(177,177),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=32)\n",
    "\n",
    "valid_generator_aug = train_datagen_aug.flow_from_directory(validation_dir,\n",
    "                                                    target_size=(177,177),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d1b1c8-e443-41c1-a36b-8b773e8245f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_VGG_aug = VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    " input_shape=(177,177,3),\n",
    "    classes=8 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9e29e7-9b7d-4e4c-82c4-237df64e8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_VGG_aug.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9806fa33-8d7f-4db1-8303-04553663f7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_VGG_aug = models.Sequential()\n",
    "model_VGG_aug.add(conv_base_VGG_aug)\n",
    "model_VGG_aug.add(Flatten())\n",
    "model_VGG_aug.add(Dense(128, activation='relu')) \n",
    "model_VGG_aug.add(Dropout(0.2))\n",
    "model_VGG_aug.add(Dense(8, activation='softmax'))#7 categories of facial emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5286a43-567c-4018-848d-3dc5530ee907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG_aug.compile(optimizer='adam',#sgd\n",
    "             loss=tf.losses.categorical_crossentropy,\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292bf5d2-58ac-4179-8880-f147ecf140a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",\n",
    "                                        mode =\"min\", \n",
    "                                        patience = 10)#the number of epochs to stop after we see no improvments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc8b8ae0-0dd2-42bc-9666-8e808aa92b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1174/1174 [==============================] - 1543s 1s/step - loss: 2.0237 - acc: 0.1956 - val_loss: 1.9743 - val_acc: 0.2260\n",
      "Epoch 2/100\n",
      "1174/1174 [==============================] - 730s 621ms/step - loss: 1.9795 - acc: 0.2139 - val_loss: 1.9658 - val_acc: 0.2145\n",
      "Epoch 3/100\n",
      "1174/1174 [==============================] - 748s 637ms/step - loss: 1.9617 - acc: 0.2252 - val_loss: 1.9278 - val_acc: 0.2450\n",
      "Epoch 4/100\n",
      "1174/1174 [==============================] - 728s 620ms/step - loss: 1.9503 - acc: 0.2324 - val_loss: 1.9338 - val_acc: 0.2303\n",
      "Epoch 5/100\n",
      "1174/1174 [==============================] - 732s 623ms/step - loss: 1.9482 - acc: 0.2349 - val_loss: 1.9220 - val_acc: 0.2450\n",
      "Epoch 6/100\n",
      "1174/1174 [==============================] - 746s 635ms/step - loss: 1.9417 - acc: 0.2391 - val_loss: 1.9101 - val_acc: 0.2455\n",
      "Epoch 7/100\n",
      "1174/1174 [==============================] - 735s 626ms/step - loss: 1.9400 - acc: 0.2384 - val_loss: 1.9101 - val_acc: 0.2528\n",
      "Epoch 8/100\n",
      "1174/1174 [==============================] - 733s 624ms/step - loss: 1.9365 - acc: 0.2372 - val_loss: 1.9200 - val_acc: 0.2463\n",
      "Epoch 9/100\n",
      "1174/1174 [==============================] - 736s 627ms/step - loss: 1.9374 - acc: 0.2388 - val_loss: 1.9071 - val_acc: 0.2405\n",
      "Epoch 10/100\n",
      "1174/1174 [==============================] - 730s 622ms/step - loss: 1.9355 - acc: 0.2422 - val_loss: 1.9104 - val_acc: 0.2435\n",
      "Epoch 11/100\n",
      "1174/1174 [==============================] - 745s 634ms/step - loss: 1.9310 - acc: 0.2439 - val_loss: 1.9098 - val_acc: 0.2370\n",
      "Epoch 12/100\n",
      "1174/1174 [==============================] - 731s 622ms/step - loss: 1.9307 - acc: 0.2457 - val_loss: 1.9111 - val_acc: 0.2477\n",
      "Epoch 13/100\n",
      "1174/1174 [==============================] - 732s 623ms/step - loss: 1.9318 - acc: 0.2420 - val_loss: 1.8966 - val_acc: 0.2573\n",
      "Epoch 14/100\n",
      "1174/1174 [==============================] - 732s 623ms/step - loss: 1.9307 - acc: 0.2424 - val_loss: 1.8985 - val_acc: 0.2580\n",
      "Epoch 15/100\n",
      "1174/1174 [==============================] - 731s 623ms/step - loss: 1.9277 - acc: 0.2464 - val_loss: 1.8981 - val_acc: 0.2558\n",
      "Epoch 16/100\n",
      "1174/1174 [==============================] - 739s 629ms/step - loss: 1.9266 - acc: 0.2451 - val_loss: 1.9110 - val_acc: 0.2528\n",
      "Epoch 17/100\n",
      "1156/1174 [============================>.] - ETA: 10s - loss: 1.9304 - acc: 0.2439"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_VGG_aug \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_VGG_aug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_VGG_aug = model_VGG_aug.fit(train_generator_aug,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator_aug,\n",
    "                   callbacks =[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a459f27-abd6-4934-96ab-50e3936391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_VGG_aug.history['acc']\n",
    "val_acc = history_VGG_aug.history['val_acc']\n",
    "loss = history_VGG_aug.history['loss']\n",
    "val_loss = history_VGG_aug.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8dfbd-fddd-4eb0-bf21-9fc7ca098f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history_VGG_aug.history) \n",
    "\n",
    "# # save to json:  \n",
    "# hist_json_file = 'history_RESNET_before.json' \n",
    "# with open(hist_json_file, mode='w') as f:\n",
    "#     hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'history_VGG_aug_before_transfer.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "    \n",
    "#pd.read_csv('history_RESNET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9487c-1147-4295-b5b1-47fb595143ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG_aug.trainable=True\n",
    "set_trainable=False\n",
    "for layer in model_VGG_aug.layers:\n",
    "    if layer.name =='block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e55a4-bbef-4663-9982-82abb13b049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",\n",
    "                                        mode =\"min\", \n",
    "                                        patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e349c-0e37-4d0b-a75d-635b795c12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 200\n",
    "history_vgg_aug_after_transfer = model_VGG_aug.fit(train_generator_aug,\n",
    "                    epochs=num_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator_aug,\n",
    "                   callbacks =[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c20544-9bc9-4207-9d00-66d2ed92fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_vgg_aug_after_transfer.history['acc']\n",
    "val_acc = history_vgg_aug_after_transfer.history['val_acc']\n",
    "loss = history_vgg_aug_after_transfer.history['loss']\n",
    "val_loss = history_vgg_aug_after_transfer.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e7e83-f59f-4fea-bdd7-8e02b0d783fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history_vgg_aug_after_transfer.history) \n",
    "\n",
    "# # save to json:  \n",
    "# hist_json_file = 'history_RESNET_before.json' \n",
    "# with open(hist_json_file, mode='w') as f:\n",
    "#     hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'history_vgg_aug_after_transfer.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "    \n",
    "#pd.read_csv('history_RESNET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1bb085-35c6-4ad0-9e52-e453b02fe7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa37abb-5797-4be6-9528-57e2810bcec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model_VGG_aug.save('results/VGG_with_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beae47f-2844-4325-ae2f-70128764b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model_VGG_aug_loaded = tf.keras.models.load_model('results/VGG_with_aug')\n",
    "# Check its architecture\n",
    "model_seq_aug_loaded.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
